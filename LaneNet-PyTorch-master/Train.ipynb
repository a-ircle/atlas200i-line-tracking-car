{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as ops\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "from dataset.dataset_utils import TUSIMPLE\n",
    "from Lanenet.model2 import Lanenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from glob import glob\n",
    "\n",
    "# # 根路径，根据你自己的路径修改\n",
    "# root_dir = '/root/car_data_new'\n",
    "# image_dir = os.path.join(root_dir, 'all_image')\n",
    "# binary_dir = os.path.join(root_dir, 'binaries')\n",
    "# instance_dir = os.path.join(root_dir, 'instances')\n",
    "# output_txt = os.path.join(root_dir, 'train.txt')\n",
    "\n",
    "# # 获取所有图像文件\n",
    "# image_paths = sorted(glob(os.path.join(image_dir, '*.png')))\n",
    "\n",
    "# valid_lines = []\n",
    "# invalid_count = 0\n",
    "\n",
    "# for img_path in image_paths:\n",
    "#     basename = os.path.basename(img_path).replace('.png', '')\n",
    "\n",
    "#     binary_path = os.path.join(binary_dir, f'{basename}_bin.png')\n",
    "#     instance_path = os.path.join(instance_dir, f'{basename}_inst.png')\n",
    "\n",
    "#     if os.path.exists(img_path) and os.path.exists(binary_path) and os.path.exists(instance_path):\n",
    "#         valid_lines.append(f'{img_path} {binary_path} {instance_path}\\n')\n",
    "#     else:\n",
    "#         print(f\"[SKIP] Missing file for: {basename}\")\n",
    "#         invalid_count += 1\n",
    "\n",
    "# # 写入 train.txt\n",
    "# with open(output_txt, 'w') as f:\n",
    "#     f.writelines(valid_lines)\n",
    "\n",
    "# print(f\"✅ train.txt saved to: {output_txt}\")\n",
    "# print(f\"Total samples written: {len(valid_lines)}\")\n",
    "# print(f\"Total skipped due to missing files: {invalid_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "\n",
    "# root = '/root/car_data_new'\n",
    "# full_txt = os.path.join(root, 'train_all.txt')  # 这里认为 train.txt 是全量文件\n",
    "# train_txt = os.path.join(root, 'train.txt')\n",
    "# val_txt = os.path.join(root, 'val.txt')\n",
    "# test_txt = os.path.join(root, 'test.txt')\n",
    "\n",
    "# # 读取所有行\n",
    "# with open(full_txt, 'r') as f:\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# # 打乱\n",
    "# random.shuffle(lines)\n",
    "\n",
    "# # 按比例切分\n",
    "# num_total = len(lines)\n",
    "# num_val = int(num_total * 0.15)\n",
    "# num_test = int(num_total * 0.15)\n",
    "# num_train = num_total - num_val - num_test\n",
    "\n",
    "# train_lines = lines[:num_train]\n",
    "# val_lines = lines[num_train:num_train + num_val]\n",
    "# test_lines = lines[num_train + num_val:]\n",
    "\n",
    "# # 写回文件\n",
    "# with open(train_txt, 'w') as f:\n",
    "#     f.writelines(train_lines)\n",
    "# with open(val_txt, 'w') as f:\n",
    "#     f.writelines(val_lines)\n",
    "# with open(test_txt, 'w') as f:\n",
    "#     f.writelines(test_lines)\n",
    "\n",
    "# print(f\"✅ 划分完成！共 {num_total} 条：\")\n",
    "# print(f\"- train: {len(train_lines)}\")\n",
    "# print(f\"- val: {len(val_lines)}\")\n",
    "# print(f\"- test: {len(test_lines)}\")\n",
    "# print(f\"文件已写入：\\n{train_txt}\\n{val_txt}\\n{test_txt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set length 12480\n",
      "valid_set length 2673\n",
      "test_set length 2673\n"
     ]
    }
   ],
   "source": [
    "# root = '/Users/smiffy/Documents/GitHub/TUSIMPLE/Data_Tusimple_PyTorch/training'\n",
    "# root = r'D:\\Camel\\project\\LaneNet-pytorch\\LaneNet-PyTorch-master\\Datasets\\TUSimple\\txt_for_local'\n",
    "root = '/root/car_data_new' # 根据自己的文件路径修改\n",
    "train_set = TUSIMPLE(root=root, flag='train')\n",
    "valid_set = TUSIMPLE(root=root, flag='valid')\n",
    "test_set = TUSIMPLE(root=root, flag='test')\n",
    "\n",
    "print('train_set length {}'.format(len(train_set)))\n",
    "print('valid_set length {}'.format(len(valid_set)))\n",
    "print('test_set length {}'.format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image type <class 'torch.Tensor'>\n",
      "image size torch.Size([3, 256, 512]) \n",
      "\n",
      "gt binary image type <class 'torch.Tensor'>\n",
      "gt binary image size torch.Size([256, 512])\n",
      "items in gt binary image tensor([0, 1]) \n",
      "\n",
      "gt instance type <class 'torch.Tensor'>\n",
      "gt instance size torch.Size([256, 512])\n",
      "items in gt instance tensor([0, 1, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt, bgt, igt = train_set[0]\n",
    "print('image type {}'.format(type(gt)))\n",
    "print('image size {} \\n'.format(gt.size()))\n",
    "\n",
    "print('gt binary image type {}'.format(type(bgt)))\n",
    "print('gt binary image size {}'.format(bgt.size()))\n",
    "print('items in gt binary image {} \\n'.format(torch.unique(bgt)))\n",
    "\n",
    "print('gt instance type {}'.format(type(igt)))\n",
    "print('gt instance size {}'.format(igt.size()))\n",
    "print('items in gt instance {} \\n'.format(torch.unique(igt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "data_loader_valid = torch.utils.data.DataLoader(valid_set, batch_size=1, shuffle=True, num_workers=0)\n",
    "data_loader_test = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 5e-4\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22086/2640266430.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_weights = torch.load(r'/root/LaneNet-Pytorch-teach/LaneNet-PyTorch-master/TUSIMPLE/Lanenet_output/lanenet_epoch_39_batch_8.model', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "LaneNet_model = Lanenet(2, 4)\n",
    "LaneNet_model.to(device)\n",
    "\n",
    "# 加载预训练权重，根据自己的文件路径进行修改\n",
    "pretrained_weights = torch.load(r'/root/LaneNet-Pytorch-teach/LaneNet-PyTorch-master/TUSIMPLE/Lanenet_output/lanenet_epoch_39_batch_8.model', map_location=device)\n",
    "\n",
    "LaneNet_model.load_state_dict(pretrained_weights, strict=False)  # strict=False 允许部分加载\n",
    "\n",
    "params = [p for p in LaneNet_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=0.0002)\n",
    "\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "# num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lanenet.cluster_loss3 import cluster_loss\n",
    "criterion = cluster_loss()\n",
    "# criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([ 1.4393, 27.7296]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] iter[0] loss: [0.2898155450820923, 2.586794376373291] \n",
      "epoch[0] iter[20] loss: [0.14328134059906006, 1.5154448747634888] \n",
      "epoch[0] iter[40] loss: [0.10189362615346909, 1.5068167448043823] \n",
      "epoch[0] iter[60] loss: [0.10000944137573242, 1.2225239276885986] \n",
      "epoch[0] iter[80] loss: [0.10364742577075958, 1.405290126800537] \n",
      "epoch[0] iter[100] loss: [0.07227662950754166, 0.6386340856552124] \n",
      "epoch[0] iter[120] loss: [0.05441936478018761, 0.2995402216911316] \n",
      "epoch[0] iter[140] loss: [0.0805426612496376, 0.6908308267593384] \n",
      "epoch[0] iter[160] loss: [0.059871409088373184, 0.2584933638572693] \n",
      "epoch[0] iter[180] loss: [0.05753929913043976, 0.38846227526664734] \n",
      "epoch[0] iter[200] loss: [0.05283370241522789, 0.20694951713085175] \n",
      "epoch[0] iter[220] loss: [0.08315527439117432, 1.0504672527313232] \n",
      "epoch[0] iter[240] loss: [0.05940543860197067, 0.17231574654579163] \n",
      "epoch[0] iter[260] loss: [0.057399436831474304, 0.19819945096969604] \n",
      "epoch[0] iter[280] loss: [0.06495485454797745, 0.24674656987190247] \n",
      "epoch[0] iter[300] loss: [0.0711444690823555, 0.2785463333129883] \n",
      "epoch[0] iter[320] loss: [0.045557714998722076, 0.1838439702987671] \n",
      "epoch[0] iter[340] loss: [0.05236300453543663, 0.14733946323394775] \n",
      "epoch[0] iter[360] loss: [0.04712551459670067, 0.1817857176065445] \n",
      "epoch[0] iter[380] loss: [0.057588666677474976, 0.5740377306938171] \n",
      "epoch[0] iter[400] loss: [0.059769172221422195, 0.5261739492416382] \n",
      "epoch[0] iter[420] loss: [0.11123184859752655, 1.2764016389846802] \n",
      "epoch[0] iter[440] loss: [0.05274151638150215, 0.3415928781032562] \n",
      "epoch[0] iter[460] loss: [0.08275251090526581, 0.7486521601676941] \n",
      "epoch[0] iter[480] loss: [0.051833152770996094, 0.21201743185520172] \n",
      "epoch[0] iter[500] loss: [0.05897725000977516, 0.31598588824272156] \n",
      "epoch[0] iter[520] loss: [0.06268352270126343, 0.6696786880493164] \n",
      "epoch[0] iter[540] loss: [0.0474986769258976, 0.15183085203170776] \n",
      "epoch[0] iter[560] loss: [0.05674884468317032, 0.18448935449123383] \n",
      "epoch[0] iter[580] loss: [0.04392772167921066, 0.13252896070480347] \n",
      "epoch[0] iter[600] loss: [0.05496646463871002, 0.1506059616804123] \n",
      "epoch[0] iter[620] loss: [0.04986477643251419, 0.18261148035526276] \n",
      "epoch[0] iter[640] loss: [0.06711529940366745, 0.32574400305747986] \n",
      "epoch[0] iter[660] loss: [0.0441012866795063, 0.11142311990261078] \n",
      "epoch[0] iter[680] loss: [0.05193639546632767, 0.1298498809337616] \n",
      "epoch[0] iter[700] loss: [0.06117682158946991, 0.3002592921257019] \n",
      "epoch[0] iter[720] loss: [0.052721764892339706, 0.17479780316352844] \n",
      "epoch[0] iter[740] loss: [0.07288522273302078, 0.4355583190917969] \n",
      "epoch[0] iter[760] loss: [0.04140656813979149, 0.17632979154586792] \n",
      "epoch[0] iter[780] loss: [0.042392831295728683, 0.12620492279529572] \n",
      "epoch[0] iter[800] loss: [0.06088264286518097, 0.6572628021240234] \n",
      "epoch[0] iter[820] loss: [0.049956418573856354, 0.17799928784370422] \n",
      "epoch[0] iter[840] loss: [0.04821969196200371, 0.13772378861904144] \n",
      "epoch[0] iter[860] loss: [0.05355706810951233, 0.15730667114257812] \n",
      "epoch[0] iter[880] loss: [0.04497573897242546, 0.18635737895965576] \n",
      "epoch[0] iter[900] loss: [0.0624246746301651, 0.21146076917648315] \n",
      "epoch[0] iter[920] loss: [0.04626535251736641, 0.14986224472522736] \n",
      "epoch[0] iter[940] loss: [0.05671326443552971, 0.3560182452201843] \n",
      "epoch[0] iter[960] loss: [0.04693041369318962, 0.48030373454093933] \n",
      "epoch[0] iter[980] loss: [0.04583039879798889, 0.12058541178703308] \n",
      "epoch[0] iter[1000] loss: [0.05268365517258644, 0.613375186920166] \n",
      "epoch[0] iter[1020] loss: [0.04508998990058899, 0.13413868844509125] \n",
      "epoch[0] iter[1040] loss: [0.0505073256790638, 0.11913657188415527] \n",
      "epoch[0] iter[1060] loss: [0.048097945749759674, 0.13175123929977417] \n",
      "epoch[0] iter[1080] loss: [0.04776136204600334, 0.11145554482936859] \n",
      "epoch[0] iter[1100] loss: [0.0429815948009491, 0.1430007964372635] \n",
      "epoch[0] iter[1120] loss: [0.053614530712366104, 0.11479567736387253] \n",
      "epoch[0] iter[1140] loss: [0.03739563375711441, 0.11020104587078094] \n",
      "epoch[0] iter[1160] loss: [0.05140809342265129, 0.1623256951570511] \n",
      "epoch[0] iter[1180] loss: [0.056663744151592255, 0.2792493999004364] \n",
      "epoch[0] iter[1200] loss: [0.04579545557498932, 0.12340448796749115] \n",
      "epoch[0] iter[1220] loss: [0.05585259571671486, 0.3915708363056183] \n",
      "epoch[0] iter[1240] loss: [0.0416245311498642, 0.10469584167003632] \n",
      "epoch[0] iter[1260] loss: [0.06029049679636955, 0.22458937764167786] \n",
      "epoch[0] iter[1280] loss: [0.049778759479522705, 0.19310957193374634] \n",
      "epoch[0] iter[1300] loss: [0.03997553512454033, 0.11620534956455231] \n",
      "epoch[0] iter[1320] loss: [0.04455645754933357, 0.12034226953983307] \n",
      "epoch[0] iter[1340] loss: [0.05226072296500206, 0.15180480480194092] \n",
      "epoch[0] iter[1360] loss: [0.05028019845485687, 0.17237606644630432] \n",
      "epoch[0] iter[1380] loss: [0.04349851980805397, 0.19856016337871552] \n",
      "epoch[0] iter[1400] loss: [0.03964269161224365, 0.10470480471849442] \n",
      "epoch[0] iter[1420] loss: [0.04711536318063736, 0.14903321862220764] \n",
      "epoch[0] iter[1440] loss: [0.0502399280667305, 0.15226374566555023] \n",
      "epoch[0] iter[1460] loss: [0.04794299602508545, 0.12693151831626892] \n",
      "epoch[0] iter[1480] loss: [0.05834093689918518, 0.3216538727283478] \n",
      "epoch[0] iter[1500] loss: [0.04934115707874298, 0.16390393674373627] \n",
      "epoch[0] iter[1520] loss: [0.042052678763866425, 0.1521461308002472] \n",
      "epoch[0] iter[1540] loss: [0.061138816177845, 0.5367031097412109] \n",
      "Finish epoch[0], time elapsed[358.1698842048645]\n",
      "epoch[1] iter[0] loss: [0.054299794137477875, 0.2062149941921234] \n",
      "epoch[1] iter[20] loss: [0.04128772392868996, 0.12150003015995026] \n",
      "epoch[1] iter[40] loss: [0.041144341230392456, 0.10204214602708817] \n",
      "epoch[1] iter[60] loss: [0.04808754846453667, 0.14670757949352264] \n",
      "epoch[1] iter[80] loss: [0.046117689460515976, 0.1215638592839241] \n",
      "epoch[1] iter[100] loss: [0.047052785754203796, 0.11575190722942352] \n",
      "epoch[1] iter[120] loss: [0.046731702983379364, 0.12589558959007263] \n",
      "epoch[1] iter[140] loss: [0.04136297479271889, 0.11318687349557877] \n",
      "epoch[1] iter[160] loss: [0.07250028103590012, 0.23600934445858002] \n",
      "epoch[1] iter[180] loss: [0.038764119148254395, 0.09057804942131042] \n",
      "epoch[1] iter[200] loss: [0.04881260544061661, 0.09642268717288971] \n",
      "epoch[1] iter[220] loss: [0.059598054736852646, 0.1896665394306183] \n",
      "epoch[1] iter[240] loss: [0.04030042141675949, 0.19772516191005707] \n",
      "epoch[1] iter[260] loss: [0.05054907128214836, 0.12427201867103577] \n",
      "epoch[1] iter[280] loss: [0.03788619488477707, 0.1149730384349823] \n",
      "epoch[1] iter[300] loss: [0.05210081487894058, 0.1702343225479126] \n",
      "epoch[1] iter[320] loss: [0.03559263423085213, 0.09790372848510742] \n",
      "epoch[1] iter[340] loss: [0.05636512115597725, 0.28205135464668274] \n",
      "epoch[1] iter[360] loss: [0.033811964094638824, 0.10285333544015884] \n",
      "epoch[1] iter[380] loss: [0.04615947976708412, 0.15627944469451904] \n",
      "epoch[1] iter[400] loss: [0.04155249521136284, 0.10707668215036392] \n",
      "epoch[1] iter[420] loss: [0.041422903537750244, 0.1077113002538681] \n",
      "epoch[1] iter[440] loss: [0.05935981124639511, 0.4333263635635376] \n",
      "epoch[1] iter[460] loss: [0.042442671954631805, 0.10893993079662323] \n",
      "epoch[1] iter[480] loss: [0.03907454013824463, 0.11817530542612076] \n",
      "epoch[1] iter[500] loss: [0.04614673927426338, 0.09451212733983994] \n",
      "epoch[1] iter[520] loss: [0.03857336938381195, 0.13953448832035065] \n",
      "epoch[1] iter[540] loss: [0.04320449382066727, 0.09603877365589142] \n",
      "epoch[1] iter[560] loss: [0.04580606892704964, 0.12204664945602417] \n",
      "epoch[1] iter[580] loss: [0.04300626739859581, 0.1165269985795021] \n",
      "epoch[1] iter[600] loss: [0.04024010896682739, 0.11286111921072006] \n",
      "epoch[1] iter[620] loss: [0.05779881775379181, 0.14721104502677917] \n",
      "epoch[1] iter[640] loss: [0.037069980055093765, 0.093959741294384] \n",
      "epoch[1] iter[660] loss: [0.04511497542262077, 0.09298508614301682] \n",
      "epoch[1] iter[680] loss: [0.03576771169900894, 0.09569717943668365] \n",
      "epoch[1] iter[700] loss: [0.04458358883857727, 0.16666746139526367] \n",
      "epoch[1] iter[720] loss: [0.03895142301917076, 0.11194943636655807] \n",
      "epoch[1] iter[740] loss: [0.0441073514521122, 0.10399436950683594] \n",
      "epoch[1] iter[760] loss: [0.04459664225578308, 0.12190227210521698] \n",
      "epoch[1] iter[780] loss: [0.04811912775039673, 0.13978993892669678] \n",
      "epoch[1] iter[800] loss: [0.05138067901134491, 0.23137912154197693] \n",
      "epoch[1] iter[820] loss: [0.05486283078789711, 0.2745498716831207] \n",
      "epoch[1] iter[840] loss: [0.04590640217065811, 0.23716433346271515] \n",
      "epoch[1] iter[860] loss: [0.04525301605463028, 0.0923774465918541] \n",
      "epoch[1] iter[880] loss: [0.042275916785001755, 0.11112657934427261] \n",
      "epoch[1] iter[900] loss: [0.04628552496433258, 0.10748499631881714] \n",
      "epoch[1] iter[920] loss: [0.04112669453024864, 0.12178274989128113] \n",
      "epoch[1] iter[940] loss: [0.04463326558470726, 0.10171066224575043] \n",
      "epoch[1] iter[960] loss: [0.046693816781044006, 0.09347609430551529] \n",
      "epoch[1] iter[980] loss: [0.04928027093410492, 0.09950597584247589] \n",
      "epoch[1] iter[1000] loss: [0.04430130869150162, 0.09869398921728134] \n",
      "epoch[1] iter[1020] loss: [0.047563858330249786, 0.123665951192379] \n",
      "epoch[1] iter[1040] loss: [0.04854917526245117, 0.11872203648090363] \n",
      "epoch[1] iter[1060] loss: [0.040601812303066254, 0.11775192618370056] \n",
      "epoch[1] iter[1080] loss: [0.041889261454343796, 0.11992359906435013] \n",
      "epoch[1] iter[1100] loss: [0.04026537016034126, 0.1173265352845192] \n",
      "epoch[1] iter[1120] loss: [0.04241174831986427, 0.10028327256441116] \n",
      "epoch[1] iter[1140] loss: [0.04132241755723953, 0.10740716010332108] \n",
      "epoch[1] iter[1160] loss: [0.0643974095582962, 0.30853942036628723] \n",
      "epoch[1] iter[1180] loss: [0.03939467668533325, 0.0964961126446724] \n",
      "epoch[1] iter[1200] loss: [0.03831745684146881, 0.08762576431035995] \n",
      "epoch[1] iter[1220] loss: [0.042086679488420486, 0.10970253497362137] \n",
      "epoch[1] iter[1240] loss: [0.049730319529771805, 0.15183773636817932] \n",
      "epoch[1] iter[1260] loss: [0.037609029561281204, 0.08784613013267517] \n",
      "epoch[1] iter[1280] loss: [0.03905126824975014, 0.10500530898571014] \n",
      "epoch[1] iter[1300] loss: [0.050284191966056824, 0.10484105348587036] \n",
      "epoch[1] iter[1320] loss: [0.0469944067299366, 0.14281484484672546] \n",
      "epoch[1] iter[1340] loss: [0.041713934391736984, 0.08627189695835114] \n",
      "epoch[1] iter[1360] loss: [0.03636053204536438, 0.08539396524429321] \n",
      "epoch[1] iter[1380] loss: [0.041232336312532425, 0.11169561743736267] \n",
      "epoch[1] iter[1400] loss: [0.04134470224380493, 0.11312920600175858] \n",
      "epoch[1] iter[1420] loss: [0.03995742276310921, 0.08840129524469376] \n",
      "epoch[1] iter[1440] loss: [0.052288975566625595, 0.17262177169322968] \n",
      "epoch[1] iter[1460] loss: [0.056658439338207245, 0.1287364661693573] \n",
      "epoch[1] iter[1480] loss: [0.03383263573050499, 0.08875161409378052] \n",
      "epoch[1] iter[1500] loss: [0.04144570976495743, 0.10913285613059998] \n",
      "epoch[1] iter[1520] loss: [0.06061724200844765, 0.2905343472957611] \n",
      "epoch[1] iter[1540] loss: [0.04118405655026436, 0.09737944602966309] \n",
      "Finish epoch[1], time elapsed[352.74596071243286]\n",
      "epoch[2] iter[0] loss: [0.04635683819651604, 0.10293073952198029] \n",
      "epoch[2] iter[20] loss: [0.042325519025325775, 0.10226509720087051] \n",
      "epoch[2] iter[40] loss: [0.05012169107794762, 0.1826682835817337] \n",
      "epoch[2] iter[60] loss: [0.03833158314228058, 0.09136456251144409] \n",
      "epoch[2] iter[80] loss: [0.0453067272901535, 0.09418691694736481] \n",
      "epoch[2] iter[100] loss: [0.039123643189668655, 0.08058688044548035] \n",
      "epoch[2] iter[120] loss: [0.046172890812158585, 0.10477563738822937] \n",
      "epoch[2] iter[140] loss: [0.050992757081985474, 0.1377294361591339] \n",
      "epoch[2] iter[160] loss: [0.04591839760541916, 0.09867789596319199] \n",
      "epoch[2] iter[180] loss: [0.038099825382232666, 0.14522427320480347] \n",
      "epoch[2] iter[200] loss: [0.04215077683329582, 0.13036639988422394] \n",
      "epoch[2] iter[220] loss: [0.054401662200689316, 0.4113028645515442] \n",
      "epoch[2] iter[240] loss: [0.03888909891247749, 0.10981360822916031] \n",
      "epoch[2] iter[260] loss: [0.04644417017698288, 0.10996100306510925] \n",
      "epoch[2] iter[280] loss: [0.039718180894851685, 0.09731331467628479] \n",
      "epoch[2] iter[300] loss: [0.03558764606714249, 0.11255648732185364] \n",
      "epoch[2] iter[320] loss: [0.03786884993314743, 0.09551148861646652] \n",
      "epoch[2] iter[340] loss: [0.035593945533037186, 0.0924968346953392] \n",
      "epoch[2] iter[360] loss: [0.03700152784585953, 0.08903403580188751] \n",
      "epoch[2] iter[380] loss: [0.03279540687799454, 0.09780915826559067] \n",
      "epoch[2] iter[400] loss: [0.04058724269270897, 0.1485087126493454] \n",
      "epoch[2] iter[420] loss: [0.0598197877407074, 0.4315618872642517] \n",
      "epoch[2] iter[440] loss: [0.04662175849080086, 0.09956280142068863] \n",
      "epoch[2] iter[460] loss: [0.04073770344257355, 0.08016909658908844] \n",
      "epoch[2] iter[480] loss: [0.04643848165869713, 0.15432675182819366] \n",
      "epoch[2] iter[500] loss: [0.04386567696928978, 0.1139836311340332] \n",
      "epoch[2] iter[520] loss: [0.040402188897132874, 0.13776268064975739] \n",
      "epoch[2] iter[540] loss: [0.049717873334884644, 0.2506011426448822] \n",
      "epoch[2] iter[560] loss: [0.04436580836772919, 0.12318824976682663] \n",
      "epoch[2] iter[580] loss: [0.05888424813747406, 0.19535726308822632] \n",
      "epoch[2] iter[600] loss: [0.038952603936195374, 0.16407477855682373] \n",
      "epoch[2] iter[620] loss: [0.046975184231996536, 0.11948855966329575] \n",
      "epoch[2] iter[640] loss: [0.038646094501018524, 0.08469519019126892] \n",
      "epoch[2] iter[660] loss: [0.06802716851234436, 0.40034130215644836] \n",
      "epoch[2] iter[680] loss: [0.03460308909416199, 0.08787078410387039] \n",
      "epoch[2] iter[700] loss: [0.04236971214413643, 0.0817456766963005] \n",
      "epoch[2] iter[720] loss: [0.03565208241343498, 0.08795914798974991] \n",
      "epoch[2] iter[740] loss: [0.03860700502991676, 0.1441062092781067] \n",
      "epoch[2] iter[760] loss: [0.04386448860168457, 0.09088930487632751] \n",
      "epoch[2] iter[780] loss: [0.03887259587645531, 0.09018412232398987] \n",
      "epoch[2] iter[800] loss: [0.0401001013815403, 0.10406183451414108] \n",
      "epoch[2] iter[820] loss: [0.05128044635057449, 0.1309954822063446] \n",
      "epoch[2] iter[840] loss: [0.041083723306655884, 0.09402471780776978] \n",
      "epoch[2] iter[860] loss: [0.04717881232500076, 0.09164407104253769] \n",
      "epoch[2] iter[880] loss: [0.0435199998319149, 0.2104613035917282] \n",
      "epoch[2] iter[900] loss: [0.07848965376615524, 0.36894917488098145] \n",
      "epoch[2] iter[920] loss: [0.0426509864628315, 0.08652424812316895] \n",
      "epoch[2] iter[940] loss: [0.037242911756038666, 0.10641740262508392] \n",
      "epoch[2] iter[960] loss: [0.041018832474946976, 0.10382732003927231] \n",
      "epoch[2] iter[980] loss: [0.0416388139128685, 0.08931125700473785] \n",
      "epoch[2] iter[1000] loss: [0.049541763961315155, 0.26106756925582886] \n",
      "epoch[2] iter[1020] loss: [0.040331654250621796, 0.09732948243618011] \n",
      "epoch[2] iter[1040] loss: [0.03697372227907181, 0.10846061259508133] \n",
      "epoch[2] iter[1060] loss: [0.05338849872350693, 0.1542433202266693] \n",
      "epoch[2] iter[1080] loss: [0.04442800208926201, 0.23452500998973846] \n",
      "epoch[2] iter[1100] loss: [0.036161743104457855, 0.08678247034549713] \n",
      "epoch[2] iter[1120] loss: [0.03867897391319275, 0.12676933407783508] \n",
      "epoch[2] iter[1140] loss: [0.04154227301478386, 0.1027919352054596] \n",
      "epoch[2] iter[1160] loss: [0.040461380034685135, 0.09878337383270264] \n",
      "epoch[2] iter[1180] loss: [0.03979358449578285, 0.08969716727733612] \n",
      "epoch[2] iter[1200] loss: [0.028844082728028297, 0.129061758518219] \n",
      "epoch[2] iter[1220] loss: [0.033296242356300354, 0.08084467798471451] \n",
      "epoch[2] iter[1240] loss: [0.03946312516927719, 0.08128838241100311] \n",
      "epoch[2] iter[1260] loss: [0.04299313202500343, 0.10288166254758835] \n",
      "epoch[2] iter[1280] loss: [0.04104841500520706, 0.09462520480155945] \n",
      "epoch[2] iter[1300] loss: [0.054528046399354935, 0.26439279317855835] \n",
      "epoch[2] iter[1320] loss: [0.03724777698516846, 0.08576051890850067] \n",
      "epoch[2] iter[1340] loss: [0.04557773098349571, 0.1117810532450676] \n",
      "epoch[2] iter[1360] loss: [0.051478054374456406, 0.16449803113937378] \n",
      "epoch[2] iter[1380] loss: [0.0416497103869915, 0.20621992647647858] \n",
      "epoch[2] iter[1400] loss: [0.0377219095826149, 0.08795899152755737] \n",
      "epoch[2] iter[1420] loss: [0.03713000938296318, 0.110463447868824] \n",
      "epoch[2] iter[1440] loss: [0.04962987080216408, 0.10745979100465775] \n",
      "epoch[2] iter[1460] loss: [0.0441611111164093, 0.11244335025548935] \n",
      "epoch[2] iter[1480] loss: [0.04056352749466896, 0.08073669672012329] \n",
      "epoch[2] iter[1500] loss: [0.04939279705286026, 0.2919478714466095] \n",
      "epoch[2] iter[1520] loss: [0.0383797362446785, 0.09773635119199753] \n",
      "epoch[2] iter[1540] loss: [0.03873811662197113, 0.14449258148670197] \n",
      "Finish epoch[2], time elapsed[353.87505626678467]\n",
      "epoch[3] iter[0] loss: [0.05287187546491623, 0.18653464317321777] \n",
      "epoch[3] iter[20] loss: [0.030448591336607933, 0.06764934957027435] \n",
      "epoch[3] iter[40] loss: [0.03585600107908249, 0.07782184332609177] \n",
      "epoch[3] iter[60] loss: [0.032392922788858414, 0.07277841120958328] \n",
      "epoch[3] iter[80] loss: [0.040139779448509216, 0.14759016036987305] \n",
      "epoch[3] iter[100] loss: [0.032643403857946396, 0.08951661735773087] \n",
      "epoch[3] iter[120] loss: [0.0359157957136631, 0.08578679710626602] \n",
      "epoch[3] iter[140] loss: [0.04308023303747177, 0.0919559970498085] \n",
      "epoch[3] iter[160] loss: [0.0362350232899189, 0.08983853459358215] \n",
      "epoch[3] iter[180] loss: [0.049395956099033356, 0.10798992216587067] \n",
      "epoch[3] iter[200] loss: [0.04133089631795883, 0.12664836645126343] \n",
      "epoch[3] iter[220] loss: [0.029804296791553497, 0.09541185200214386] \n",
      "epoch[3] iter[240] loss: [0.0422377735376358, 0.1384286731481552] \n",
      "epoch[3] iter[260] loss: [0.04137416183948517, 0.11376407742500305] \n",
      "epoch[3] iter[280] loss: [0.0410396046936512, 0.10666819661855698] \n",
      "epoch[3] iter[300] loss: [0.04362194240093231, 0.0975373312830925] \n",
      "epoch[3] iter[320] loss: [0.0373382493853569, 0.09912878274917603] \n",
      "epoch[3] iter[340] loss: [0.042851824313402176, 0.08330708742141724] \n",
      "epoch[3] iter[360] loss: [0.037091732025146484, 0.08753391355276108] \n",
      "epoch[3] iter[380] loss: [0.05558270588517189, 0.14829929172992706] \n",
      "epoch[3] iter[400] loss: [0.03982382267713547, 0.09283119440078735] \n",
      "epoch[3] iter[420] loss: [0.04119851440191269, 0.09086976945400238] \n",
      "epoch[3] iter[440] loss: [0.03749539330601692, 0.08874591439962387] \n",
      "epoch[3] iter[460] loss: [0.040247783064842224, 0.09456288814544678] \n",
      "epoch[3] iter[480] loss: [0.045187704265117645, 0.0918973982334137] \n",
      "epoch[3] iter[500] loss: [0.040252719074487686, 0.094545878469944] \n",
      "epoch[3] iter[520] loss: [0.03170686587691307, 0.07975892722606659] \n",
      "epoch[3] iter[540] loss: [0.041917070746421814, 0.1830955296754837] \n",
      "epoch[3] iter[560] loss: [0.03916963189840317, 0.08371146768331528] \n",
      "epoch[3] iter[580] loss: [0.03893612325191498, 0.08532475680112839] \n",
      "epoch[3] iter[600] loss: [0.04123130813241005, 0.0958636924624443] \n",
      "epoch[3] iter[620] loss: [0.040546417236328125, 0.07630059123039246] \n",
      "epoch[3] iter[640] loss: [0.034092970192432404, 0.09751637279987335] \n",
      "epoch[3] iter[660] loss: [0.04023859649896622, 0.15294544398784637] \n",
      "epoch[3] iter[680] loss: [0.04075393080711365, 0.18523317575454712] \n",
      "epoch[3] iter[700] loss: [0.04515731707215309, 0.18088287115097046] \n",
      "epoch[3] iter[720] loss: [0.03896322473883629, 0.09751182049512863] \n",
      "epoch[3] iter[740] loss: [0.060438547283411026, 0.19621515274047852] \n",
      "epoch[3] iter[760] loss: [0.038113292306661606, 0.09370936453342438] \n",
      "epoch[3] iter[780] loss: [0.05207456648349762, 0.18905648589134216] \n",
      "epoch[3] iter[800] loss: [0.033838845789432526, 0.08765830844640732] \n",
      "epoch[3] iter[820] loss: [0.031723782420158386, 0.08334328979253769] \n",
      "epoch[3] iter[840] loss: [0.04517184570431709, 0.13692812621593475] \n",
      "epoch[3] iter[860] loss: [0.040578410029411316, 0.08953504264354706] \n",
      "epoch[3] iter[880] loss: [0.06053042411804199, 0.2252999097108841] \n",
      "epoch[3] iter[900] loss: [0.03833213075995445, 0.08000769466161728] \n",
      "epoch[3] iter[920] loss: [0.03743534907698631, 0.11861271411180496] \n",
      "epoch[3] iter[940] loss: [0.04352109134197235, 0.0888744369149208] \n",
      "epoch[3] iter[960] loss: [0.04508431255817413, 0.07919438928365707] \n",
      "epoch[3] iter[980] loss: [0.040358345955610275, 0.10074172914028168] \n",
      "epoch[3] iter[1000] loss: [0.040428467094898224, 0.08808794617652893] \n",
      "epoch[3] iter[1020] loss: [0.035616353154182434, 0.1304902881383896] \n",
      "epoch[3] iter[1040] loss: [0.04399403557181358, 0.09662653505802155] \n",
      "epoch[3] iter[1060] loss: [0.038853663951158524, 0.0821901485323906] \n",
      "epoch[3] iter[1080] loss: [0.031735021620988846, 0.08274129033088684] \n",
      "epoch[3] iter[1100] loss: [0.03299250081181526, 0.08926891535520554] \n",
      "epoch[3] iter[1120] loss: [0.04797866940498352, 0.11718088388442993] \n",
      "epoch[3] iter[1140] loss: [0.03548794984817505, 0.07542384415864944] \n",
      "epoch[3] iter[1160] loss: [0.046458836644887924, 0.09206708520650864] \n",
      "epoch[3] iter[1180] loss: [0.039229992777109146, 0.08647540211677551] \n",
      "epoch[3] iter[1200] loss: [0.04494863748550415, 0.08942323178052902] \n",
      "epoch[3] iter[1220] loss: [0.05014093220233917, 0.09554069489240646] \n",
      "epoch[3] iter[1240] loss: [0.05485871061682701, 0.33739110827445984] \n",
      "epoch[3] iter[1260] loss: [0.047167178243398666, 0.17627175152301788] \n",
      "epoch[3] iter[1280] loss: [0.05939070135354996, 0.25977832078933716] \n",
      "epoch[3] iter[1300] loss: [0.03736099973320961, 0.11317939311265945] \n",
      "epoch[3] iter[1320] loss: [0.03803776204586029, 0.07956530898809433] \n",
      "epoch[3] iter[1340] loss: [0.03672245144844055, 0.09217674285173416] \n",
      "epoch[3] iter[1360] loss: [0.04031272605061531, 0.08821064233779907] \n",
      "epoch[3] iter[1380] loss: [0.04023478925228119, 0.10121692717075348] \n",
      "epoch[3] iter[1400] loss: [0.047671884298324585, 0.15481622517108917] \n",
      "epoch[3] iter[1420] loss: [0.04513338580727577, 0.10689656436443329] \n",
      "epoch[3] iter[1440] loss: [0.05473365634679794, 0.18393808603286743] \n",
      "epoch[3] iter[1460] loss: [0.042328182607889175, 0.12169930338859558] \n",
      "epoch[3] iter[1480] loss: [0.04669353365898132, 0.08096753060817719] \n",
      "epoch[3] iter[1500] loss: [0.03647293895483017, 0.08336460590362549] \n",
      "epoch[3] iter[1520] loss: [0.03494991734623909, 0.08481863141059875] \n",
      "epoch[3] iter[1540] loss: [0.03404189646244049, 0.07935908436775208] \n",
      "Finish epoch[3], time elapsed[353.1361894607544]\n",
      "epoch[4] iter[0] loss: [0.03261088207364082, 0.08509733527898788] \n",
      "epoch[4] iter[20] loss: [0.043453000485897064, 0.07222215831279755] \n",
      "epoch[4] iter[40] loss: [0.035301417112350464, 0.07579049468040466] \n",
      "epoch[4] iter[60] loss: [0.05795510113239288, 0.35337111353874207] \n",
      "epoch[4] iter[80] loss: [0.04106568917632103, 0.07956252247095108] \n",
      "epoch[4] iter[100] loss: [0.04180512577295303, 0.0748891532421112] \n",
      "epoch[4] iter[120] loss: [0.03917636722326279, 0.06901808083057404] \n",
      "epoch[4] iter[140] loss: [0.04192150756716728, 0.17262142896652222] \n",
      "epoch[4] iter[160] loss: [0.0438288114964962, 0.09016427397727966] \n",
      "epoch[4] iter[180] loss: [0.035433489829301834, 0.07392207533121109] \n",
      "epoch[4] iter[200] loss: [0.04192380607128143, 0.09150748699903488] \n",
      "epoch[4] iter[220] loss: [0.038001205772161484, 0.14493893086910248] \n",
      "epoch[4] iter[240] loss: [0.04356721043586731, 0.09752544015645981] \n",
      "epoch[4] iter[260] loss: [0.035724710673093796, 0.08842524886131287] \n",
      "epoch[4] iter[280] loss: [0.043731048703193665, 0.10198798775672913] \n",
      "epoch[4] iter[300] loss: [0.0357365608215332, 0.08301921933889389] \n",
      "epoch[4] iter[320] loss: [0.04100826755166054, 0.06647421419620514] \n",
      "epoch[4] iter[340] loss: [0.0360323041677475, 0.08313944935798645] \n",
      "epoch[4] iter[360] loss: [0.041886359453201294, 0.0950842797756195] \n",
      "epoch[4] iter[380] loss: [0.03698160871863365, 0.12347068637609482] \n",
      "epoch[4] iter[400] loss: [0.04176510497927666, 0.07760591804981232] \n",
      "epoch[4] iter[420] loss: [0.03572528064250946, 0.07863355427980423] \n",
      "epoch[4] iter[440] loss: [0.04076249152421951, 0.0880819633603096] \n",
      "epoch[4] iter[460] loss: [0.03855520114302635, 0.08392003178596497] \n",
      "epoch[4] iter[480] loss: [0.03987538069486618, 0.11886660754680634] \n",
      "epoch[4] iter[500] loss: [0.046721383929252625, 0.15684154629707336] \n",
      "epoch[4] iter[520] loss: [0.0406469963490963, 0.07327250391244888] \n",
      "epoch[4] iter[540] loss: [0.037395015358924866, 0.08298169821500778] \n",
      "epoch[4] iter[560] loss: [0.03824251517653465, 0.07001448422670364] \n",
      "epoch[4] iter[580] loss: [0.04167532920837402, 0.11248209327459335] \n",
      "epoch[4] iter[600] loss: [0.03409877419471741, 0.12221956253051758] \n",
      "epoch[4] iter[620] loss: [0.03931916132569313, 0.07788610458374023] \n",
      "epoch[4] iter[640] loss: [0.04372164607048035, 0.11080796271562576] \n",
      "epoch[4] iter[660] loss: [0.036102596670389175, 0.08272310346364975] \n",
      "epoch[4] iter[680] loss: [0.04207904264330864, 0.07424166798591614] \n",
      "epoch[4] iter[700] loss: [0.037052400410175323, 0.10211572051048279] \n",
      "epoch[4] iter[720] loss: [0.04207196086645126, 0.09298842400312424] \n",
      "epoch[4] iter[740] loss: [0.053695812821388245, 0.1180967167019844] \n",
      "epoch[4] iter[760] loss: [0.03200839087367058, 0.08455729484558105] \n",
      "epoch[4] iter[780] loss: [0.03787216544151306, 0.07632049173116684] \n",
      "epoch[4] iter[800] loss: [0.03906654193997383, 0.07311595231294632] \n",
      "epoch[4] iter[820] loss: [0.03494761511683464, 0.07385478168725967] \n",
      "epoch[4] iter[840] loss: [0.053058892488479614, 0.2659568786621094] \n",
      "epoch[4] iter[860] loss: [0.03596935048699379, 0.09320993721485138] \n",
      "epoch[4] iter[880] loss: [0.040034111589193344, 0.07777068018913269] \n",
      "epoch[4] iter[900] loss: [0.051806025207042694, 0.1709728091955185] \n",
      "epoch[4] iter[920] loss: [0.03881343826651573, 0.09190445393323898] \n",
      "epoch[4] iter[940] loss: [0.04188665375113487, 0.08234580606222153] \n",
      "epoch[4] iter[960] loss: [0.037889037281274796, 0.09434546530246735] \n",
      "epoch[4] iter[980] loss: [0.05487706512212753, 0.11782414466142654] \n",
      "epoch[4] iter[1000] loss: [0.03662227466702461, 0.07435498386621475] \n",
      "epoch[4] iter[1020] loss: [0.043515466153621674, 0.259870707988739] \n",
      "epoch[4] iter[1040] loss: [0.04263172298669815, 0.08068684488534927] \n",
      "epoch[4] iter[1060] loss: [0.0532243438065052, 0.23932498693466187] \n",
      "epoch[4] iter[1080] loss: [0.03924541175365448, 0.08887800574302673] \n",
      "epoch[4] iter[1100] loss: [0.04028788581490517, 0.08368765562772751] \n",
      "epoch[4] iter[1120] loss: [0.04301285371184349, 0.08669280260801315] \n",
      "epoch[4] iter[1140] loss: [0.03626666218042374, 0.07933998107910156] \n",
      "epoch[4] iter[1160] loss: [0.04597732052206993, 0.08906634151935577] \n",
      "epoch[4] iter[1180] loss: [0.053465478122234344, 0.10618805885314941] \n",
      "epoch[4] iter[1200] loss: [0.03853926062583923, 0.0953710526227951] \n",
      "epoch[4] iter[1220] loss: [0.04648827388882637, 0.1058359369635582] \n",
      "epoch[4] iter[1240] loss: [0.03716517984867096, 0.0794224813580513] \n",
      "epoch[4] iter[1260] loss: [0.044200390577316284, 0.09821175038814545] \n",
      "epoch[4] iter[1280] loss: [0.03881927207112312, 0.0765380784869194] \n",
      "epoch[4] iter[1300] loss: [0.030260762199759483, 0.06796818971633911] \n",
      "epoch[4] iter[1320] loss: [0.03843230754137039, 0.08994808793067932] \n",
      "epoch[4] iter[1340] loss: [0.052245695143938065, 0.11199742555618286] \n",
      "epoch[4] iter[1360] loss: [0.04441263526678085, 0.12104551494121552] \n",
      "epoch[4] iter[1380] loss: [0.03605642914772034, 0.08560647815465927] \n",
      "epoch[4] iter[1400] loss: [0.036114223301410675, 0.07795649766921997] \n",
      "epoch[4] iter[1420] loss: [0.03692995384335518, 0.08188482373952866] \n",
      "epoch[4] iter[1440] loss: [0.0461433008313179, 0.11186578869819641] \n",
      "epoch[4] iter[1460] loss: [0.04127311706542969, 0.09971035271883011] \n",
      "epoch[4] iter[1480] loss: [0.04145702347159386, 0.07475929707288742] \n",
      "epoch[4] iter[1500] loss: [0.040183521807193756, 0.08274607360363007] \n",
      "epoch[4] iter[1520] loss: [0.03547900915145874, 0.1771818846464157] \n",
      "epoch[4] iter[1540] loss: [0.04356550797820091, 0.06954517960548401] \n",
      "Finish epoch[4], time elapsed[353.30044198036194]\n"
     ]
    }
   ],
   "source": [
    "loss_all = []\n",
    "for epoch in range(num_epochs):\n",
    "    LaneNet_model.train()\n",
    "    ts = time.time()\n",
    "    for iter, batch in enumerate(data_loader_train):\n",
    "        input_image = batch[0].to(device)\n",
    "        binary_labels = batch[1].to(device)\n",
    "        instance_labels = batch[2].to(device)\n",
    "        \n",
    "        binary_final_logits, instance_embedding = LaneNet_model(input_image)\n",
    "        # loss = LaneNet_model.compute_loss(binary_logits=binary_final_logits, binary_labels=binary_labels,\n",
    "        #                               instance_logits=instance_embedding, instance_labels=instance_labels, delta_v=0.5, delta_d=3)\n",
    "        binary_segmenatation_loss, instance_segmenatation_loss = criterion(binary_logits=binary_final_logits, binary_labels=binary_labels,\n",
    "                                       instance_logits=instance_embedding, instance_labels=instance_labels, delta_v=0.5, delta_d=3)\n",
    "        \n",
    "        # binary_segmenatation_loss = criterion(binary_final_logits, binary_labels)\n",
    "        loss = 1*binary_segmenatation_loss + 1*instance_segmenatation_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss_all.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if iter % 20 == 0:\n",
    "            print(\"epoch[{}] iter[{}] loss: [{}, {}] \".format(epoch, iter, binary_segmenatation_loss.item(), instance_segmenatation_loss.item()))\n",
    "    lr_scheduler.step()\n",
    "    print(\"Finish epoch[{}], time elapsed[{}]\".format(epoch, time.time() - ts))\n",
    "    torch.save(LaneNet_model.state_dict(), \n",
    "                       f\"TUSIMPLE/Lanenet_output/lanenet_my_improve_{epoch}_batch_{8}.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f31246ca4e0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.plot(loss_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX模型转换\n",
    "文件在transform.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
