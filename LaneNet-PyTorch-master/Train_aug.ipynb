{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as ops\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "from dataset.dataset_utils import TUSIMPLE, TUSIMPLE_AUG\n",
    "from Lanenet.model2 import Lanenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build The datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set length 24960\n",
      "valid_set length 5346\n",
      "test_set length 5346\n"
     ]
    }
   ],
   "source": [
    "# root = '/Users/smiffy/Documents/GitHub/TUSIMPLE/Data_Tusimple_PyTorch/training'\n",
    "# root = 'TUSIMPLE/txt_for_local'\n",
    "root = '/root/car_data_new'\n",
    "train_set = TUSIMPLE_AUG(root=root, flag='train')\n",
    "valid_set = TUSIMPLE_AUG(root=root, flag='valid')\n",
    "test_set = TUSIMPLE_AUG(root=root, flag='test')\n",
    "\n",
    "print('train_set length {}'.format(len(train_set)))\n",
    "print('valid_set length {}'.format(len(valid_set)))\n",
    "print('test_set length {}'.format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image type <class 'torch.Tensor'>\n",
      "image size torch.Size([3, 256, 512]) \n",
      "\n",
      "gt binary image type <class 'torch.Tensor'>\n",
      "gt binary image size torch.Size([256, 512])\n",
      "items in gt binary image tensor([0, 1]) \n",
      "\n",
      "gt instance type <class 'torch.Tensor'>\n",
      "gt instance size torch.Size([256, 512])\n",
      "items in gt instance tensor([0, 1, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt, bgt, igt = train_set[0]\n",
    "print('image type {}'.format(type(gt)))\n",
    "print('image size {} \\n'.format(gt.size()))\n",
    "\n",
    "print('gt binary image type {}'.format(type(bgt)))\n",
    "print('gt binary image size {}'.format(bgt.size()))\n",
    "print('items in gt binary image {} \\n'.format(torch.unique(bgt)))\n",
    "\n",
    "print('gt instance type {}'.format(type(igt)))\n",
    "print('gt instance size {}'.format(igt.size()))\n",
    "print('items in gt instance {} \\n'.format(torch.unique(igt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "data_loader_valid = torch.utils.data.DataLoader(valid_set, batch_size=1, shuffle=True, num_workers=0)\n",
    "data_loader_test = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29737/1561641026.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_weights = torch.load(r'/root/LaneNet-Pytorch-teach/LaneNet-PyTorch-master/TUSIMPLE/Lanenet_output/lanenet_epoch_8_batch_8_AUG.model', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "LaneNet_model = Lanenet(2, 4)\n",
    "LaneNet_model.to(device)\n",
    "pretrained_weights = torch.load(r'/root/LaneNet-Pytorch-teach/LaneNet-PyTorch-master/TUSIMPLE/Lanenet_output/lanenet_epoch_8_batch_8_AUG.model', map_location=device)\n",
    "\n",
    "LaneNet_model.load_state_dict(pretrained_weights, strict=False)  # strict=False 允许部分加载\n",
    "\n",
    "params = [p for p in LaneNet_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=0.0002)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "# num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lanenet.cluster_loss3 import cluster_loss\n",
    "criterion = cluster_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[15] iter[0] loss: [0.035351820290088654, 0.07591531425714493] \n",
      "epoch[15] iter[40] loss: [0.043126486241817474, 0.08433555066585541] \n",
      "epoch[15] iter[80] loss: [0.043740808963775635, 0.0753730833530426] \n",
      "epoch[15] iter[120] loss: [0.04542377218604088, 0.07998567819595337] \n",
      "epoch[15] iter[160] loss: [0.05016503855586052, 0.12438071519136429] \n",
      "epoch[15] iter[200] loss: [0.034828487783670425, 0.0616428405046463] \n",
      "epoch[15] iter[240] loss: [0.04155220091342926, 0.07879751920700073] \n",
      "epoch[15] iter[280] loss: [0.04113888740539551, 0.07766755670309067] \n",
      "epoch[15] iter[320] loss: [0.04462040215730667, 0.07655412703752518] \n",
      "epoch[15] iter[360] loss: [0.04090138524770737, 0.09088414162397385] \n",
      "epoch[15] iter[400] loss: [0.0389535166323185, 0.06785660982131958] \n",
      "epoch[15] iter[440] loss: [0.05328337475657463, 0.25530388951301575] \n",
      "epoch[15] iter[480] loss: [0.04090871289372444, 0.07279812544584274] \n",
      "epoch[15] iter[520] loss: [0.04140777885913849, 0.09478525817394257] \n",
      "epoch[15] iter[560] loss: [0.046257343143224716, 0.07487520575523376] \n",
      "epoch[15] iter[600] loss: [0.04383515939116478, 0.069920115172863] \n",
      "epoch[15] iter[640] loss: [0.037486784160137177, 0.06509707123041153] \n",
      "epoch[15] iter[680] loss: [0.044723618775606155, 0.0788111537694931] \n",
      "epoch[15] iter[720] loss: [0.037321124225854874, 0.07066439092159271] \n",
      "epoch[15] iter[760] loss: [0.03382966294884682, 0.12230024486780167] \n",
      "epoch[15] iter[800] loss: [0.036026179790496826, 0.08088157325983047] \n",
      "epoch[15] iter[840] loss: [0.040079884231090546, 0.0755690410733223] \n",
      "epoch[15] iter[880] loss: [0.049539901316165924, 0.07539387047290802] \n",
      "epoch[15] iter[920] loss: [0.04518871381878853, 0.08658193796873093] \n",
      "epoch[15] iter[960] loss: [0.03646189719438553, 0.07361074537038803] \n",
      "epoch[15] iter[1000] loss: [0.03598587214946747, 0.06771694868803024] \n",
      "epoch[15] iter[1040] loss: [0.0427958220243454, 0.07784418761730194] \n",
      "epoch[15] iter[1080] loss: [0.04011077433824539, 0.10080163180828094] \n",
      "epoch[15] iter[1120] loss: [0.036130212247371674, 0.08652158081531525] \n",
      "epoch[15] iter[1160] loss: [0.04239090904593468, 0.22979280352592468] \n",
      "epoch[15] iter[1200] loss: [0.041376687586307526, 0.1482217013835907] \n",
      "epoch[15] iter[1240] loss: [0.03876884654164314, 0.12080159783363342] \n",
      "epoch[15] iter[1280] loss: [0.04257791489362717, 0.09084896743297577] \n",
      "epoch[15] iter[1320] loss: [0.03609282895922661, 0.09300750494003296] \n",
      "epoch[15] iter[1360] loss: [0.04392881691455841, 0.08292409777641296] \n",
      "epoch[15] iter[1400] loss: [0.03651529550552368, 0.08692656457424164] \n",
      "epoch[15] iter[1440] loss: [0.035207949578762054, 0.07475856691598892] \n",
      "epoch[15] iter[1480] loss: [0.04861906170845032, 0.15796895325183868] \n",
      "epoch[15] iter[1520] loss: [0.0367630235850811, 0.06582843512296677] \n",
      "epoch[15] iter[1560] loss: [0.043101370334625244, 0.08416564762592316] \n",
      "epoch[15] iter[1600] loss: [0.042708978056907654, 0.07297096401453018] \n",
      "epoch[15] iter[1640] loss: [0.04034372419118881, 0.1138756200671196] \n",
      "epoch[15] iter[1680] loss: [0.03522934392094612, 0.08140441030263901] \n",
      "epoch[15] iter[1720] loss: [0.03915543481707573, 0.0797058716416359] \n",
      "epoch[15] iter[1760] loss: [0.03352585434913635, 0.06079214811325073] \n",
      "epoch[15] iter[1800] loss: [0.07746293395757675, 0.23611673712730408] \n",
      "epoch[15] iter[1840] loss: [0.05798975005745888, 0.20139802992343903] \n",
      "epoch[15] iter[1880] loss: [0.032197847962379456, 0.07405970990657806] \n",
      "epoch[15] iter[1920] loss: [0.048280879855155945, 0.08255432546138763] \n",
      "epoch[15] iter[1960] loss: [0.04753273352980614, 0.08219177275896072] \n",
      "epoch[15] iter[2000] loss: [0.044723331928253174, 0.09041181951761246] \n",
      "epoch[15] iter[2040] loss: [0.04102063551545143, 0.08672898262739182] \n",
      "epoch[15] iter[2080] loss: [0.033159684389829636, 0.06263234466314316] \n",
      "epoch[15] iter[2120] loss: [0.0390520915389061, 0.06015370041131973] \n",
      "epoch[15] iter[2160] loss: [0.03524554893374443, 0.07445055991411209] \n",
      "epoch[15] iter[2200] loss: [0.049472011625766754, 0.0776519626379013] \n",
      "epoch[15] iter[2240] loss: [0.03825002908706665, 0.08587850630283356] \n",
      "epoch[15] iter[2280] loss: [0.04346805810928345, 0.07731873542070389] \n",
      "epoch[15] iter[2320] loss: [0.049478836357593536, 0.13756254315376282] \n",
      "epoch[15] iter[2360] loss: [0.04036179184913635, 0.0579390674829483] \n",
      "epoch[15] iter[2400] loss: [0.04058077558875084, 0.09417366981506348] \n",
      "epoch[15] iter[2440] loss: [0.03357426077127457, 0.07774890214204788] \n",
      "epoch[15] iter[2480] loss: [0.038239143788814545, 0.06072612106800079] \n",
      "epoch[15] iter[2520] loss: [0.042004093527793884, 0.08943410962820053] \n",
      "epoch[15] iter[2560] loss: [0.0485798679292202, 0.11451752483844757] \n",
      "epoch[15] iter[2600] loss: [0.03874187916517258, 0.0684552937746048] \n",
      "epoch[15] iter[2640] loss: [0.04428669810295105, 0.1095137819647789] \n",
      "epoch[15] iter[2680] loss: [0.03995208442211151, 0.08415251225233078] \n",
      "epoch[15] iter[2720] loss: [0.039603251963853836, 0.07029344141483307] \n",
      "epoch[15] iter[2760] loss: [0.03703194484114647, 0.06704504787921906] \n",
      "epoch[15] iter[2800] loss: [0.03624812141060829, 0.06467466056346893] \n",
      "epoch[15] iter[2840] loss: [0.035622306168079376, 0.11862943321466446] \n",
      "epoch[15] iter[2880] loss: [0.03852563351392746, 0.06873427331447601] \n",
      "epoch[15] iter[2920] loss: [0.047187644988298416, 0.09078995883464813] \n",
      "epoch[15] iter[2960] loss: [0.04431929811835289, 0.08652447909116745] \n",
      "epoch[15] iter[3000] loss: [0.03429223224520683, 0.07086268067359924] \n",
      "epoch[15] iter[3040] loss: [0.044447511434555054, 0.08040596544742584] \n",
      "epoch[15] iter[3080] loss: [0.03503197804093361, 0.09440982341766357] \n",
      "Finish epoch[15], time elapsed[727.0990326404572]\n",
      "epoch[16] iter[0] loss: [0.04101552441716194, 0.07805640995502472] \n",
      "epoch[16] iter[40] loss: [0.036393728107213974, 0.07875470817089081] \n",
      "epoch[16] iter[80] loss: [0.038084112107753754, 0.07734168320894241] \n",
      "epoch[16] iter[120] loss: [0.03991559520363808, 0.07365988940000534] \n",
      "epoch[16] iter[160] loss: [0.040345631539821625, 0.07229727506637573] \n",
      "epoch[16] iter[200] loss: [0.04384387284517288, 0.09150877594947815] \n",
      "epoch[16] iter[240] loss: [0.03855000436306, 0.09232868999242783] \n",
      "epoch[16] iter[280] loss: [0.03646808862686157, 0.06879948824644089] \n",
      "epoch[16] iter[320] loss: [0.03818915784358978, 0.06733447313308716] \n",
      "epoch[16] iter[360] loss: [0.03534567356109619, 0.0747038945555687] \n",
      "epoch[16] iter[400] loss: [0.03640032187104225, 0.0796862468123436] \n",
      "epoch[16] iter[440] loss: [0.03589295968413353, 0.08894283324480057] \n",
      "epoch[16] iter[480] loss: [0.04071471467614174, 0.07819844037294388] \n",
      "epoch[16] iter[520] loss: [0.030715642496943474, 0.0776512399315834] \n",
      "epoch[16] iter[560] loss: [0.0398935005068779, 0.10964211821556091] \n",
      "epoch[16] iter[600] loss: [0.036422740668058395, 0.0653984472155571] \n",
      "epoch[16] iter[640] loss: [0.0446942001581192, 0.07619079202413559] \n",
      "epoch[16] iter[680] loss: [0.04007886350154877, 0.07036647945642471] \n",
      "epoch[16] iter[720] loss: [0.03642267361283302, 0.07924104481935501] \n",
      "epoch[16] iter[760] loss: [0.040327396243810654, 0.07322755455970764] \n",
      "epoch[16] iter[800] loss: [0.04531002417206764, 0.12228939682245255] \n",
      "epoch[16] iter[840] loss: [0.035127442330121994, 0.06307962536811829] \n",
      "epoch[16] iter[880] loss: [0.03701597452163696, 0.0722319707274437] \n",
      "epoch[16] iter[920] loss: [0.037803150713443756, 0.06378594040870667] \n",
      "epoch[16] iter[960] loss: [0.0358826145529747, 0.08090204745531082] \n",
      "epoch[16] iter[1000] loss: [0.03405221924185753, 0.0705554336309433] \n",
      "epoch[16] iter[1040] loss: [0.03923618420958519, 0.08202407509088516] \n",
      "epoch[16] iter[1080] loss: [0.034606292843818665, 0.0763692557811737] \n",
      "epoch[16] iter[1120] loss: [0.039101406931877136, 0.08188982307910919] \n",
      "epoch[16] iter[1160] loss: [0.04802050068974495, 0.13376079499721527] \n",
      "epoch[16] iter[1200] loss: [0.037780486047267914, 0.080856092274189] \n",
      "epoch[16] iter[1240] loss: [0.039824072271585464, 0.10423724353313446] \n",
      "epoch[16] iter[1280] loss: [0.04016996920108795, 0.07355229556560516] \n",
      "epoch[16] iter[1320] loss: [0.04492052271962166, 0.13139377534389496] \n",
      "epoch[16] iter[1360] loss: [0.0393533930182457, 0.09041284769773483] \n",
      "epoch[16] iter[1400] loss: [0.042741116136312485, 0.06855955719947815] \n",
      "epoch[16] iter[1440] loss: [0.04877713322639465, 0.16286899149417877] \n",
      "epoch[16] iter[1480] loss: [0.04597245901823044, 0.07310574501752853] \n",
      "epoch[16] iter[1520] loss: [0.04835887625813484, 0.07461630553007126] \n",
      "epoch[16] iter[1560] loss: [0.03982257843017578, 0.06731757521629333] \n",
      "epoch[16] iter[1600] loss: [0.036929335445165634, 0.06179811805486679] \n",
      "epoch[16] iter[1640] loss: [0.037435147911310196, 0.061228007078170776] \n",
      "epoch[16] iter[1680] loss: [0.03974626585841179, 0.0915013924241066] \n",
      "epoch[16] iter[1720] loss: [0.03322533145546913, 0.07756371051073074] \n",
      "epoch[16] iter[1760] loss: [0.04276701435446739, 0.07684232294559479] \n",
      "epoch[16] iter[1800] loss: [0.03868307173252106, 0.09069870412349701] \n",
      "epoch[16] iter[1840] loss: [0.03521911799907684, 0.05858839303255081] \n",
      "epoch[16] iter[1880] loss: [0.041831325739622116, 0.07626476138830185] \n",
      "epoch[16] iter[1920] loss: [0.05415739864110947, 0.1365361213684082] \n",
      "epoch[16] iter[1960] loss: [0.034243300557136536, 0.06332515925168991] \n",
      "epoch[16] iter[2000] loss: [0.03666142374277115, 0.08997760713100433] \n",
      "epoch[16] iter[2040] loss: [0.04211405664682388, 0.10164433717727661] \n",
      "epoch[16] iter[2080] loss: [0.0428374707698822, 0.06884797662496567] \n",
      "epoch[16] iter[2120] loss: [0.03562889248132706, 0.09427718818187714] \n",
      "epoch[16] iter[2160] loss: [0.03685425594449043, 0.07754555344581604] \n",
      "epoch[16] iter[2200] loss: [0.0449458546936512, 0.07817947864532471] \n",
      "epoch[16] iter[2240] loss: [0.040357403457164764, 0.08773644268512726] \n",
      "epoch[16] iter[2280] loss: [0.036743149161338806, 0.07019152492284775] \n",
      "epoch[16] iter[2320] loss: [0.04147401824593544, 0.08785304427146912] \n",
      "epoch[16] iter[2360] loss: [0.04347168281674385, 0.10793114453554153] \n",
      "epoch[16] iter[2400] loss: [0.03743276745080948, 0.07767049223184586] \n",
      "epoch[16] iter[2440] loss: [0.03702644258737564, 0.11223885416984558] \n",
      "epoch[16] iter[2480] loss: [0.04458319768309593, 0.08803002536296844] \n",
      "epoch[16] iter[2520] loss: [0.04629156365990639, 0.07358376681804657] \n",
      "epoch[16] iter[2560] loss: [0.04387672245502472, 0.06840437650680542] \n",
      "epoch[16] iter[2600] loss: [0.03925631195306778, 0.07723166793584824] \n",
      "epoch[16] iter[2640] loss: [0.034029025584459305, 0.08894360065460205] \n",
      "epoch[16] iter[2680] loss: [0.03738537058234215, 0.07055078446865082] \n",
      "epoch[16] iter[2720] loss: [0.03484651446342468, 0.06005310267210007] \n",
      "epoch[16] iter[2760] loss: [0.039131227880716324, 0.07176254689693451] \n",
      "epoch[16] iter[2800] loss: [0.03852123022079468, 0.0843900516629219] \n",
      "epoch[16] iter[2840] loss: [0.03890453279018402, 0.07457078248262405] \n",
      "epoch[16] iter[2880] loss: [0.04235055670142174, 0.0854267105460167] \n",
      "epoch[16] iter[2920] loss: [0.0417521670460701, 0.07462851703166962] \n",
      "epoch[16] iter[2960] loss: [0.04058220237493515, 0.06870701164007187] \n",
      "epoch[16] iter[3000] loss: [0.038645267486572266, 0.08348467200994492] \n",
      "epoch[16] iter[3040] loss: [0.04114922136068344, 0.07087928056716919] \n",
      "epoch[16] iter[3080] loss: [0.03525305166840553, 0.0733736976981163] \n",
      "Finish epoch[16], time elapsed[721.7738831043243]\n",
      "epoch[17] iter[0] loss: [0.041322629898786545, 0.07155077159404755] \n",
      "epoch[17] iter[40] loss: [0.03842867538332939, 0.06620766967535019] \n",
      "epoch[17] iter[80] loss: [0.03557753935456276, 0.073118656873703] \n",
      "epoch[17] iter[120] loss: [0.04604189842939377, 0.06653863191604614] \n",
      "epoch[17] iter[160] loss: [0.0478023961186409, 0.0707114189863205] \n",
      "epoch[17] iter[200] loss: [0.03603494539856911, 0.07172247767448425] \n",
      "epoch[17] iter[240] loss: [0.041321542114019394, 0.07805934548377991] \n",
      "epoch[17] iter[280] loss: [0.03618704527616501, 0.07378258556127548] \n",
      "epoch[17] iter[320] loss: [0.03788257762789726, 0.0676296055316925] \n",
      "epoch[17] iter[360] loss: [0.045081060379743576, 0.07907924056053162] \n",
      "epoch[17] iter[400] loss: [0.039814580231904984, 0.0717543438076973] \n",
      "epoch[17] iter[440] loss: [0.03399199992418289, 0.07685904204845428] \n",
      "epoch[17] iter[480] loss: [0.04553118720650673, 0.09872925281524658] \n",
      "epoch[17] iter[520] loss: [0.04712684825062752, 0.07940097898244858] \n",
      "epoch[17] iter[560] loss: [0.03545970469713211, 0.16661690175533295] \n",
      "epoch[17] iter[600] loss: [0.04124514013528824, 0.06776301562786102] \n",
      "epoch[17] iter[640] loss: [0.03860481083393097, 0.0969412624835968] \n",
      "epoch[17] iter[680] loss: [0.044125284999608994, 0.12313568592071533] \n",
      "epoch[17] iter[720] loss: [0.04709203541278839, 0.16314922273159027] \n",
      "epoch[17] iter[760] loss: [0.04422235116362572, 0.3199620544910431] \n",
      "epoch[17] iter[800] loss: [0.05024053901433945, 0.08936893939971924] \n",
      "epoch[17] iter[840] loss: [0.04221878573298454, 0.09072193503379822] \n",
      "epoch[17] iter[880] loss: [0.037105876952409744, 0.07035379856824875] \n",
      "epoch[17] iter[920] loss: [0.04100664332509041, 0.06883660703897476] \n",
      "epoch[17] iter[960] loss: [0.03821423277258873, 0.09028063714504242] \n",
      "epoch[17] iter[1000] loss: [0.038893550634384155, 0.06549283117055893] \n",
      "epoch[17] iter[1040] loss: [0.03575997054576874, 0.06761331111192703] \n",
      "epoch[17] iter[1080] loss: [0.03980805724859238, 0.12174828350543976] \n",
      "epoch[17] iter[1120] loss: [0.04013018310070038, 0.08904443681240082] \n",
      "epoch[17] iter[1160] loss: [0.039440419524908066, 0.07187464833259583] \n",
      "epoch[17] iter[1200] loss: [0.03552866354584694, 0.0593099445104599] \n",
      "epoch[17] iter[1240] loss: [0.03736726567149162, 0.07818010449409485] \n",
      "epoch[17] iter[1280] loss: [0.03952435031533241, 0.09279823303222656] \n",
      "epoch[17] iter[1320] loss: [0.05524977296590805, 0.24303828179836273] \n",
      "epoch[17] iter[1360] loss: [0.042504843324422836, 0.08558490872383118] \n",
      "epoch[17] iter[1400] loss: [0.03731350973248482, 0.0679219663143158] \n",
      "epoch[17] iter[1440] loss: [0.042391832917928696, 0.08935372531414032] \n",
      "epoch[17] iter[1480] loss: [0.053475018590688705, 0.1418640911579132] \n",
      "epoch[17] iter[1520] loss: [0.03942011669278145, 0.07289150357246399] \n",
      "epoch[17] iter[1560] loss: [0.036544572561979294, 0.09418991208076477] \n",
      "epoch[17] iter[1600] loss: [0.04172234237194061, 0.0857226625084877] \n",
      "epoch[17] iter[1640] loss: [0.04094821959733963, 0.08798836171627045] \n",
      "epoch[17] iter[1680] loss: [0.04130927100777626, 0.07720828056335449] \n",
      "epoch[17] iter[1720] loss: [0.040908247232437134, 0.12157030403614044] \n",
      "epoch[17] iter[1760] loss: [0.03944983705878258, 0.06705930829048157] \n",
      "epoch[17] iter[1800] loss: [0.04959239438176155, 0.12738962471485138] \n",
      "epoch[17] iter[1840] loss: [0.041047822684049606, 0.09270104765892029] \n",
      "epoch[17] iter[1880] loss: [0.03615246340632439, 0.06184203922748566] \n",
      "epoch[17] iter[1920] loss: [0.03907749429345131, 0.06942479312419891] \n",
      "epoch[17] iter[1960] loss: [0.034383226186037064, 0.07979153096675873] \n",
      "epoch[17] iter[2000] loss: [0.04230666160583496, 0.0671573057770729] \n",
      "epoch[17] iter[2040] loss: [0.033982496708631516, 0.06615500897169113] \n",
      "epoch[17] iter[2080] loss: [0.034996651113033295, 0.10065791755914688] \n",
      "epoch[17] iter[2120] loss: [0.046505484730005264, 0.08652395009994507] \n",
      "epoch[17] iter[2160] loss: [0.03827425092458725, 0.08995413035154343] \n",
      "epoch[17] iter[2200] loss: [0.04261791333556175, 0.09958692640066147] \n",
      "epoch[17] iter[2240] loss: [0.036320555955171585, 0.09146375209093094] \n",
      "epoch[17] iter[2280] loss: [0.04050590470433235, 0.07472839206457138] \n",
      "epoch[17] iter[2320] loss: [0.031798042356967926, 0.08787653595209122] \n",
      "epoch[17] iter[2360] loss: [0.0357624888420105, 0.07137208431959152] \n",
      "epoch[17] iter[2400] loss: [0.03863762691617012, 0.06381101906299591] \n",
      "epoch[17] iter[2440] loss: [0.042035240679979324, 0.06957514584064484] \n",
      "epoch[17] iter[2480] loss: [0.030507484450936317, 0.06778064370155334] \n",
      "epoch[17] iter[2520] loss: [0.0762503370642662, 0.3492722809314728] \n",
      "epoch[17] iter[2560] loss: [0.035295866429805756, 0.0803159549832344] \n",
      "epoch[17] iter[2600] loss: [0.034876707941293716, 0.06713423132896423] \n",
      "epoch[17] iter[2640] loss: [0.056905053555965424, 0.39188241958618164] \n",
      "epoch[17] iter[2680] loss: [0.038715071976184845, 0.07012490928173065] \n",
      "epoch[17] iter[2720] loss: [0.04068470001220703, 0.11492666602134705] \n",
      "epoch[17] iter[2760] loss: [0.04672861471772194, 0.11425887048244476] \n",
      "epoch[17] iter[2800] loss: [0.03933282569050789, 0.06737333536148071] \n",
      "epoch[17] iter[2840] loss: [0.038428451865911484, 0.06214270740747452] \n",
      "epoch[17] iter[2880] loss: [0.04453539103269577, 0.09610284119844437] \n",
      "epoch[17] iter[2920] loss: [0.035936158150434494, 0.07525648921728134] \n",
      "epoch[17] iter[2960] loss: [0.03689366951584816, 0.06850707530975342] \n",
      "epoch[17] iter[3000] loss: [0.04053574055433273, 0.07575955241918564] \n",
      "epoch[17] iter[3040] loss: [0.035907160490751266, 0.06641734391450882] \n",
      "epoch[17] iter[3080] loss: [0.04022912681102753, 0.12637178599834442] \n",
      "Finish epoch[17], time elapsed[719.2559723854065]\n",
      "epoch[18] iter[0] loss: [0.03428077697753906, 0.0649404376745224] \n",
      "epoch[18] iter[40] loss: [0.04359688237309456, 0.06659463047981262] \n",
      "epoch[18] iter[80] loss: [0.037891730666160583, 0.06957244127988815] \n",
      "epoch[18] iter[120] loss: [0.03779333084821701, 0.06294538080692291] \n",
      "epoch[18] iter[160] loss: [0.043882887810468674, 0.06253675371408463] \n",
      "epoch[18] iter[200] loss: [0.034471746534109116, 0.07134082913398743] \n",
      "epoch[18] iter[240] loss: [0.040285658091306686, 0.07976439595222473] \n",
      "epoch[18] iter[280] loss: [0.03867579624056816, 0.06898514926433563] \n",
      "epoch[18] iter[320] loss: [0.03883323073387146, 0.08727183192968369] \n",
      "epoch[18] iter[360] loss: [0.039462894201278687, 0.08678773045539856] \n",
      "epoch[18] iter[400] loss: [0.040218744426965714, 0.08333726972341537] \n",
      "epoch[18] iter[440] loss: [0.03653126209974289, 0.06999295949935913] \n",
      "epoch[18] iter[480] loss: [0.03761254623532295, 0.07701998203992844] \n",
      "epoch[18] iter[520] loss: [0.040016304701566696, 0.07620377838611603] \n",
      "epoch[18] iter[560] loss: [0.04303824529051781, 0.07509879022836685] \n",
      "epoch[18] iter[600] loss: [0.05343329906463623, 0.20183932781219482] \n",
      "epoch[18] iter[640] loss: [0.0389200784265995, 0.061433691531419754] \n",
      "epoch[18] iter[680] loss: [0.04075578227639198, 0.06858650594949722] \n",
      "epoch[18] iter[720] loss: [0.050098076462745667, 0.0918915644288063] \n",
      "epoch[18] iter[760] loss: [0.039122074842453, 0.07544038444757462] \n",
      "epoch[18] iter[800] loss: [0.05265539139509201, 0.1294506937265396] \n",
      "epoch[18] iter[840] loss: [0.031448595225811005, 0.09038876742124557] \n",
      "epoch[18] iter[880] loss: [0.03224293515086174, 0.07080117613077164] \n",
      "epoch[18] iter[920] loss: [0.03441525623202324, 0.07016606628894806] \n",
      "epoch[18] iter[960] loss: [0.04027087613940239, 0.10716590285301208] \n",
      "epoch[18] iter[1000] loss: [0.035860929638147354, 0.08163386583328247] \n",
      "epoch[18] iter[1040] loss: [0.03770522028207779, 0.07095646113157272] \n",
      "epoch[18] iter[1080] loss: [0.04397572949528694, 0.08749190717935562] \n",
      "epoch[18] iter[1120] loss: [0.03689572960138321, 0.059597332030534744] \n",
      "epoch[18] iter[1160] loss: [0.041498441249132156, 0.08895237743854523] \n",
      "epoch[18] iter[1200] loss: [0.03634205833077431, 0.06312716007232666] \n",
      "epoch[18] iter[1240] loss: [0.03476502001285553, 0.07622794061899185] \n",
      "epoch[18] iter[1280] loss: [0.04693569242954254, 0.0846450924873352] \n",
      "epoch[18] iter[1320] loss: [0.036219242960214615, 0.06838024407625198] \n",
      "epoch[18] iter[1360] loss: [0.04173863306641579, 0.08346859365701675] \n",
      "epoch[18] iter[1400] loss: [0.038531262427568436, 0.08829829841852188] \n",
      "epoch[18] iter[1440] loss: [0.03812367096543312, 0.07144293934106827] \n",
      "epoch[18] iter[1480] loss: [0.05511734262108803, 0.13393694162368774] \n",
      "epoch[18] iter[1520] loss: [0.033029451966285706, 0.07269028574228287] \n",
      "epoch[18] iter[1560] loss: [0.04269195348024368, 0.08130457252264023] \n",
      "epoch[18] iter[1600] loss: [0.03422083705663681, 0.061783816665410995] \n",
      "epoch[18] iter[1640] loss: [0.03226247429847717, 0.07477226108312607] \n",
      "epoch[18] iter[1680] loss: [0.04004988074302673, 0.06822261214256287] \n",
      "epoch[18] iter[1720] loss: [0.035623520612716675, 0.07341327518224716] \n",
      "epoch[18] iter[1760] loss: [0.034269001334905624, 0.10038207471370697] \n",
      "epoch[18] iter[1800] loss: [0.03469396010041237, 0.06442169100046158] \n",
      "epoch[18] iter[1840] loss: [0.04376852139830589, 0.06999758630990982] \n",
      "epoch[18] iter[1880] loss: [0.03801960125565529, 0.08684799075126648] \n",
      "epoch[18] iter[1920] loss: [0.038756612688302994, 0.06951270997524261] \n",
      "epoch[18] iter[1960] loss: [0.0415758341550827, 0.08594896644353867] \n",
      "epoch[18] iter[2000] loss: [0.04516446217894554, 0.07730036973953247] \n",
      "epoch[18] iter[2040] loss: [0.04173506051301956, 0.06178756803274155] \n",
      "epoch[18] iter[2080] loss: [0.040279731154441833, 0.07910288870334625] \n",
      "epoch[18] iter[2120] loss: [0.03823063150048256, 0.09404680132865906] \n",
      "epoch[18] iter[2160] loss: [0.043354976922273636, 0.3033389449119568] \n",
      "epoch[18] iter[2200] loss: [0.04245875030755997, 0.08402357250452042] \n",
      "epoch[18] iter[2240] loss: [0.04056069999933243, 0.07517200708389282] \n",
      "epoch[18] iter[2280] loss: [0.039140939712524414, 0.07466955482959747] \n",
      "epoch[18] iter[2320] loss: [0.041581232100725174, 0.06403309851884842] \n",
      "epoch[18] iter[2360] loss: [0.04386110231280327, 0.0740974098443985] \n",
      "epoch[18] iter[2400] loss: [0.037408504635095596, 0.1255727857351303] \n",
      "epoch[18] iter[2440] loss: [0.042964957654476166, 0.09984014183282852] \n",
      "epoch[18] iter[2480] loss: [0.042345788329839706, 0.09032061696052551] \n",
      "epoch[18] iter[2520] loss: [0.03551613539457321, 0.06959881633520126] \n",
      "epoch[18] iter[2560] loss: [0.04273148998618126, 0.08630423247814178] \n",
      "epoch[18] iter[2600] loss: [0.03659360483288765, 0.07024525851011276] \n",
      "epoch[18] iter[2640] loss: [0.03311603516340256, 0.07657141238451004] \n",
      "epoch[18] iter[2680] loss: [0.03884732723236084, 0.06396617740392685] \n",
      "epoch[18] iter[2720] loss: [0.04225524514913559, 0.08363614231348038] \n",
      "epoch[18] iter[2760] loss: [0.04737769812345505, 0.0828433483839035] \n",
      "epoch[18] iter[2800] loss: [0.04139748960733414, 0.07438544929027557] \n",
      "epoch[18] iter[2840] loss: [0.04173865541815758, 0.1144777238368988] \n",
      "epoch[18] iter[2880] loss: [0.03650146350264549, 0.06305907666683197] \n",
      "epoch[18] iter[2920] loss: [0.03955254703760147, 0.09329837560653687] \n",
      "epoch[18] iter[2960] loss: [0.04169221594929695, 0.21249407529830933] \n",
      "epoch[18] iter[3000] loss: [0.03816758096218109, 0.08432406932115555] \n",
      "epoch[18] iter[3040] loss: [0.03411291539669037, 0.07365696877241135] \n",
      "epoch[18] iter[3080] loss: [0.04984916001558304, 0.10248017311096191] \n",
      "Finish epoch[18], time elapsed[716.1847252845764]\n",
      "epoch[19] iter[0] loss: [0.045029714703559875, 0.11367147415876389] \n",
      "epoch[19] iter[40] loss: [0.04311288148164749, 0.07734434306621552] \n",
      "epoch[19] iter[80] loss: [0.03450614586472511, 0.06251074373722076] \n",
      "epoch[19] iter[120] loss: [0.043202172964811325, 0.08727863430976868] \n",
      "epoch[19] iter[160] loss: [0.03914979100227356, 0.07185603678226471] \n",
      "epoch[19] iter[200] loss: [0.04150915518403053, 0.06778312474489212] \n",
      "epoch[19] iter[240] loss: [0.03837106004357338, 0.06824977695941925] \n",
      "epoch[19] iter[280] loss: [0.04190957918763161, 0.13234105706214905] \n",
      "epoch[19] iter[320] loss: [0.036078017204999924, 0.06853286176919937] \n",
      "epoch[19] iter[360] loss: [0.03956541419029236, 0.06843699514865875] \n",
      "epoch[19] iter[400] loss: [0.037085048854351044, 0.0713844895362854] \n",
      "epoch[19] iter[440] loss: [0.041451435536146164, 0.06984082609415054] \n",
      "epoch[19] iter[480] loss: [0.044864799827337265, 0.07905925810337067] \n",
      "epoch[19] iter[520] loss: [0.0370243564248085, 0.07330095022916794] \n",
      "epoch[19] iter[560] loss: [0.042987726628780365, 0.07948487997055054] \n",
      "epoch[19] iter[600] loss: [0.04115648940205574, 0.0748571902513504] \n",
      "epoch[19] iter[640] loss: [0.04539544880390167, 0.07848764955997467] \n",
      "epoch[19] iter[680] loss: [0.040178436785936356, 0.06560052931308746] \n",
      "epoch[19] iter[720] loss: [0.044517941772937775, 0.07089697569608688] \n",
      "epoch[19] iter[760] loss: [0.03952804207801819, 0.07763410359621048] \n",
      "epoch[19] iter[800] loss: [0.04233650118112564, 0.0762547180056572] \n",
      "epoch[19] iter[840] loss: [0.03147540241479874, 0.06676357239484787] \n",
      "epoch[19] iter[880] loss: [0.03900790214538574, 0.07074163109064102] \n",
      "epoch[19] iter[920] loss: [0.04504350572824478, 0.07676035165786743] \n",
      "epoch[19] iter[960] loss: [0.04555962607264519, 0.08905968070030212] \n",
      "epoch[19] iter[1000] loss: [0.04454045742750168, 0.13167861104011536] \n",
      "epoch[19] iter[1040] loss: [0.03965361416339874, 0.0631844624876976] \n",
      "epoch[19] iter[1080] loss: [0.046253498643636703, 0.10276356339454651] \n",
      "epoch[19] iter[1120] loss: [0.03681674227118492, 0.0583835169672966] \n",
      "epoch[19] iter[1160] loss: [0.04018263518810272, 0.08016008883714676] \n",
      "epoch[19] iter[1200] loss: [0.034151840955019, 0.0728665292263031] \n",
      "epoch[19] iter[1240] loss: [0.037566620856523514, 0.08152936398983002] \n",
      "epoch[19] iter[1280] loss: [0.042698122560977936, 0.07363561540842056] \n",
      "epoch[19] iter[1320] loss: [0.036735765635967255, 0.08338329195976257] \n",
      "epoch[19] iter[1360] loss: [0.032177843153476715, 0.06994318217039108] \n",
      "epoch[19] iter[1400] loss: [0.038507405668497086, 0.0702497586607933] \n",
      "epoch[19] iter[1440] loss: [0.03823487460613251, 0.07092943042516708] \n",
      "epoch[19] iter[1480] loss: [0.038133859634399414, 0.057655707001686096] \n",
      "epoch[19] iter[1520] loss: [0.03486345335841179, 0.0637919083237648] \n",
      "epoch[19] iter[1560] loss: [0.04143080487847328, 0.07383175194263458] \n",
      "epoch[19] iter[1600] loss: [0.037021711468696594, 0.08191931247711182] \n",
      "epoch[19] iter[1640] loss: [0.046017348766326904, 0.12026017159223557] \n",
      "epoch[19] iter[1680] loss: [0.03436051681637764, 0.06678575277328491] \n",
      "epoch[19] iter[1720] loss: [0.04195067286491394, 0.07412267476320267] \n",
      "epoch[19] iter[1760] loss: [0.03557179495692253, 0.07766345888376236] \n",
      "epoch[19] iter[1800] loss: [0.049284178763628006, 0.09731781482696533] \n",
      "epoch[19] iter[1840] loss: [0.03744080290198326, 0.05870409309864044] \n",
      "epoch[19] iter[1880] loss: [0.04158932715654373, 0.06763667613267899] \n",
      "epoch[19] iter[1920] loss: [0.04073425009846687, 0.07361502200365067] \n",
      "epoch[19] iter[1960] loss: [0.05826590582728386, 0.11191924661397934] \n",
      "epoch[19] iter[2000] loss: [0.06114545091986656, 0.13204516470432281] \n",
      "epoch[19] iter[2040] loss: [0.05149830877780914, 0.12354639917612076] \n",
      "epoch[19] iter[2080] loss: [0.035862721502780914, 0.06415033340454102] \n",
      "epoch[19] iter[2120] loss: [0.0433974489569664, 0.09416904300451279] \n",
      "epoch[19] iter[2160] loss: [0.03352908045053482, 0.06212425231933594] \n",
      "epoch[19] iter[2200] loss: [0.03940550237894058, 0.06071879714727402] \n",
      "epoch[19] iter[2240] loss: [0.04968918487429619, 0.10994391143321991] \n",
      "epoch[19] iter[2280] loss: [0.04811730980873108, 0.0932670459151268] \n",
      "epoch[19] iter[2320] loss: [0.042009394615888596, 0.09434645622968674] \n",
      "epoch[19] iter[2360] loss: [0.042523276060819626, 0.08775132149457932] \n",
      "epoch[19] iter[2400] loss: [0.04976464807987213, 0.1963023990392685] \n",
      "epoch[19] iter[2440] loss: [0.034530624747276306, 0.06801319867372513] \n",
      "epoch[19] iter[2480] loss: [0.04927953705191612, 0.07247862219810486] \n",
      "epoch[19] iter[2520] loss: [0.040173351764678955, 0.09949338436126709] \n",
      "epoch[19] iter[2560] loss: [0.031614694744348526, 0.0628952607512474] \n",
      "epoch[19] iter[2600] loss: [0.04266039654612541, 0.0581403449177742] \n",
      "epoch[19] iter[2640] loss: [0.029333774000406265, 0.08289892971515656] \n",
      "epoch[19] iter[2680] loss: [0.03884270042181015, 0.07917670160531998] \n",
      "epoch[19] iter[2720] loss: [0.041114240884780884, 0.057134103029966354] \n",
      "epoch[19] iter[2760] loss: [0.04255591705441475, 0.08812063187360764] \n",
      "epoch[19] iter[2800] loss: [0.0456511452794075, 0.08384969830513] \n",
      "epoch[19] iter[2840] loss: [0.035575151443481445, 0.07635356485843658] \n",
      "epoch[19] iter[2880] loss: [0.07016537338495255, 0.2573816776275635] \n",
      "epoch[19] iter[2920] loss: [0.04395747184753418, 0.07378968596458435] \n",
      "epoch[19] iter[2960] loss: [0.033639367669820786, 0.06328828632831573] \n",
      "epoch[19] iter[3000] loss: [0.043238941580057144, 0.0988214761018753] \n",
      "epoch[19] iter[3040] loss: [0.04354747384786606, 0.0939287319779396] \n",
      "epoch[19] iter[3080] loss: [0.049386993050575256, 0.08065290004014969] \n",
      "Finish epoch[19], time elapsed[715.4561030864716]\n",
      "epoch[20] iter[0] loss: [0.03393447771668434, 0.07322107255458832] \n",
      "epoch[20] iter[40] loss: [0.04866905137896538, 0.13253211975097656] \n",
      "epoch[20] iter[80] loss: [0.05624261125922203, 0.08499252051115036] \n",
      "epoch[20] iter[120] loss: [0.03964519500732422, 0.07048068195581436] \n",
      "epoch[20] iter[160] loss: [0.0372108519077301, 0.07846174389123917] \n",
      "epoch[20] iter[200] loss: [0.04709286987781525, 0.08089269697666168] \n",
      "epoch[20] iter[240] loss: [0.039912983775138855, 0.06831483542919159] \n",
      "epoch[20] iter[280] loss: [0.04222745820879936, 0.08355937153100967] \n",
      "epoch[20] iter[320] loss: [0.03723476827144623, 0.08438307046890259] \n",
      "epoch[20] iter[360] loss: [0.04399936646223068, 0.06906282901763916] \n",
      "epoch[20] iter[400] loss: [0.03844572976231575, 0.07206762582063675] \n",
      "epoch[20] iter[440] loss: [0.03943266347050667, 0.061501394957304] \n",
      "epoch[20] iter[480] loss: [0.035059455782175064, 0.06370646506547928] \n",
      "epoch[20] iter[520] loss: [0.04122303053736687, 0.06795985996723175] \n",
      "epoch[20] iter[560] loss: [0.03655170649290085, 0.06972489506006241] \n",
      "epoch[20] iter[600] loss: [0.046596214175224304, 0.08908050507307053] \n",
      "epoch[20] iter[640] loss: [0.03564133122563362, 0.07263621687889099] \n",
      "epoch[20] iter[680] loss: [0.03722766786813736, 0.1128205806016922] \n",
      "epoch[20] iter[720] loss: [0.040487583726644516, 0.06911219656467438] \n",
      "epoch[20] iter[760] loss: [0.043182674795389175, 0.09990723431110382] \n",
      "epoch[20] iter[800] loss: [0.03826223313808441, 0.08417122811079025] \n",
      "epoch[20] iter[840] loss: [0.033273689448833466, 0.06095987930893898] \n",
      "epoch[20] iter[880] loss: [0.04953285679221153, 0.24257799983024597] \n",
      "epoch[20] iter[920] loss: [0.039637692272663116, 0.06989237666130066] \n",
      "epoch[20] iter[960] loss: [0.04474537819623947, 0.06197545304894447] \n",
      "epoch[20] iter[1000] loss: [0.04257364943623543, 0.10051429271697998] \n",
      "epoch[20] iter[1040] loss: [0.038332462310791016, 0.08243045955896378] \n",
      "epoch[20] iter[1080] loss: [0.0471835620701313, 0.10641931742429733] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m loss_all\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m40\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_all = []\n",
    "for epoch in range(15,num_epochs):\n",
    "    LaneNet_model.train()\n",
    "    ts = time.time()\n",
    "    for iter, batch in enumerate(data_loader_train):\n",
    "        input_image = Variable(batch[0]).to(device)\n",
    "        binary_labels = Variable(batch[1]).to(device)\n",
    "        instance_labels = Variable(batch[2]).to(device)\n",
    "        \n",
    "        binary_final_logits, instance_embedding = LaneNet_model(input_image)\n",
    "        # loss = LaneNet_model.compute_loss(binary_logits=binary_final_logits, binary_labels=binary_labels,\n",
    "        #                               instance_logits=instance_embedding, instance_labels=instance_labels, delta_v=0.5, delta_d=3)\n",
    "        binary_segmenatation_loss, instance_segmenatation_loss = criterion(binary_logits=binary_final_logits, binary_labels=binary_labels,\n",
    "                                       instance_logits=instance_embedding, instance_labels=instance_labels, delta_v=0.5, delta_d=3)\n",
    "        \n",
    "        # binary_segmenatation_loss = criterion(binary_final_logits, binary_labels)\n",
    "        loss = 1*binary_segmenatation_loss + 1*instance_segmenatation_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss_all.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if iter % 40 == 0:\n",
    "            print(\"epoch[{}] iter[{}] loss: [{}, {}] \".format(epoch, iter, binary_segmenatation_loss.item(), instance_segmenatation_loss.item()))\n",
    "    lr_scheduler.step()\n",
    "    print(\"Finish epoch[{}], time elapsed[{}]\".format(epoch, time.time() - ts))\n",
    "    torch.save(LaneNet_model.state_dict(), \n",
    "                       f\"TUSIMPLE/Lanenet_output/lanenet_epoch_{epoch}_batch_{8}_AUG.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f54f40ad4c0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.plot(loss_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
